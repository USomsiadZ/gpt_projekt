{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bd4aef-941c-40d1-9782-88a24961fef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "konfiguracja modelu: GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch transformers numpy\n",
    "import torch\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "print(\"konfiguracja modelu:\", model.config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74494153-98fe-489e-8cd8-21b437dd65c8",
   "metadata": {},
   "source": [
    "<center><h1>Macierz embedding</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045df1d-4178-4ba9-938c-a636760b5002",
   "metadata": {},
   "source": [
    "Macierz embedding oznaczamy jako $W_E$ . Model GPT2 ma predefiniowany słownik składający się z $V = 50\\,257$ tokenów. \n",
    "\n",
    "Dla każdego z tych tokenów odpowiada jedna kolumna tej macierzy. Każda kolumna (w przypadku modelu GPT2-small) stanowi 768-wymiarowy wektor cech. Oznacza to, że macierz embedding ma wymiary $768 \\times50\\,257$. Na podstawie tego możemy obliczyć wartość wszystkich parametrów w macierzy embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51918b51-0383-4681-b20a-b8e90d8b7e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kształt macierzy embedding: torch.Size([50257, 768])\n",
      "wszystkie parametry w macierzy embedding: 38597376\n"
     ]
    }
   ],
   "source": [
    "we = model.wte.weight\n",
    "print(\"kształt macierzy embedding:\", we.shape)\n",
    "\n",
    "kolumny = we.shape[1]\n",
    "wiersze = we.shape[0]\n",
    "parametry = kolumny*wiersze\n",
    "print(\"wszystkie parametry w macierzy embedding:\", parametry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facca31c-7fb7-4759-9b42-f76a2d375db1",
   "metadata": {},
   "source": [
    "<center><h1>Macierze Q,K,V</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7cc01-2505-4b67-b019-32881aca3e7b",
   "metadata": {},
   "source": [
    "W bloku self attention wykorzystujemy trzy macierze wag, które oznaczamy jako $W_Q$ (Query), $W_K$ (Key), $W_V$ (Value). W modelu GPT2-small ich wymiary wynoszą $768 \\times768$, choć technicznie są one podzielone na niezależne podprzestrzenie zwane głowicami.\n",
    "\n",
    "Model posiada 12 głowic. Oznacza to, że obliczony wektor zapytania $q$  o długości 768 w rzeczywistości składa się z 12 mniejszych wektorów, każdy o wymiarze:\n",
    "\n",
    "<center><h4>$d_{head} = \\frac{768}{12} = 64$</h4></center>\n",
    "\n",
    "* **wiersze** odpowiadają wymiarowi wejściowemu – macierz musi przyjąć wektor embeddingu o długości 768.\n",
    "* **kolumny** odpowiadają wymiarowi wyjściowemu – wynikiem mnożenia jest nowy wektor, który również ma długość 768.\n",
    "\n",
    "Mnożąc wektor konkretnego tokena przez macierz $W_Q$ otrzymujemy wektor zapytania $q$, który szuka konkretnych cech\n",
    "\n",
    "Mnożąc wektor konkretnego tokena przez macierz $W_K$ otrzymujemy wektor klucza $k$, który reklamuje konkretne cechy\n",
    "\n",
    "Mnożąc wektor konkretnego tokena przez macierz $W_V$ otrzymujemy wektor wartości $v$, który zawiera treść, która zostanie przekazana dalej, jeśli $q$ i $k$ będą do siebie pasować.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12914af8-db26-4769-ada3-376e6024e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kształt W_Q: torch.Size([768, 768])\n",
      "kształt W_K: torch.Size([768, 768])\n",
      "kształt W_V: torch.Size([768, 768])\n",
      "\n",
      "wektor q: torch.Size([768])\n",
      "wektor k: torch.Size([768])\n",
      "wektor v: torch.Size([768])\n",
      "\n",
      "liczba głowic w modelu: 12\n",
      "rzeczywisty wymiar wektora jednej głowicy: 64\n"
     ]
    }
   ],
   "source": [
    "e = model.wte.weight[100] \n",
    "\n",
    "W_QKV = model.h[0].attn.c_attn.weight\n",
    "\n",
    "W_Q = W_QKV[:, 0:768]\n",
    "W_K = W_QKV[:, 768:1536]\n",
    "W_V = W_QKV[:, 1536:]\n",
    "print(\"kształt W_Q:\", W_Q.shape)\n",
    "print(\"kształt W_K:\", W_K.shape)\n",
    "print(\"kształt W_V:\", W_V.shape)\n",
    "\n",
    "# wektor tokena*macierz\n",
    "q = torch.matmul(e, W_Q)\n",
    "k = torch.matmul(e, W_K)\n",
    "v = torch.matmul(e, W_V)\n",
    "print(\"\")\n",
    "print(\"wektor q:\", q.shape)\n",
    "print(\"wektor k:\", k.shape)\n",
    "print(\"wektor v:\", v.shape)\n",
    "\n",
    "n_head = model.config.n_head\n",
    "head_dim = q.shape[0] // n_head\n",
    "print(\"\")\n",
    "print(\"liczba głowic w modelu:\", n_head)\n",
    "print(\"rzeczywisty wymiar wektora jednej głowicy:\", head_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.7",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
